{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow pandas matplotlib scikit-learn","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:22:36.567861Z","iopub.execute_input":"2023-05-24T05:22:36.568578Z","iopub.status.idle":"2023-05-24T05:23:04.588916Z","shell.execute_reply.started":"2023-05-24T05:22:36.568546Z","shell.execute_reply":"2023-05-24T05:23:04.587672Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.11.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.6.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (23.3.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.2.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (21.3)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (59.8.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: keras<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.29.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.0)\nRequirement already satisfied: tensorboard<2.12,>=2.11 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.11.2)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.53.0)\nCollecting protobuf<3.20,>=3.9.2\n  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (16.0.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.39.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.0.7)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.9.3)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.17.2)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.3)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.28.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.3.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.2)\nInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nkfp 1.8.20 requires google-api-python-client<2,>=1.7.8, but you have google-api-python-client 2.86.0 which is incompatible.\nkfp 1.8.20 requires PyYAML<6,>=5.3, but you have pyyaml 6.0 which is incompatible.\ngcsfs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2023.4.0 which is incompatible.\ncudf 23.4.0 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\nbeatrix-jupyterlab 2023.46.184821 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.19.6\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"pip install --upgrade \"numpy>=1.16.5,<1.23.0\"","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:04.591305Z","iopub.execute_input":"2023-05-24T05:23:04.591635Z","iopub.status.idle":"2023-05-24T05:23:20.567866Z","shell.execute_reply.started":"2023-05-24T05:23:04.591605Z","shell.execute_reply":"2023-05-24T05:23:20.566622Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting numpy<1.23.0,>=1.16.5\n  Downloading numpy-1.22.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Uninstalling numpy-1.23.5:\n      Successfully uninstalled numpy-1.23.5\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndask-cudf 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\ncuml 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\ncudf 23.4.0 requires cupy-cuda11x<12.0.0a0,>=9.5.0, which is not installed.\nraft-dask 23.4.0 requires dask==2023.3.2, but you have dask 2023.4.0 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.22.4 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.9.3 which is incompatible.\nonnx 1.13.1 requires protobuf<4,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\nlibrosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\ndask-cudf 23.4.0 requires dask==2023.3.2, but you have dask 2023.4.0 which is incompatible.\ndask-cuda 23.4.0 requires dask==2023.3.2, but you have dask 2023.4.0 which is incompatible.\ncuml 23.4.0 requires dask==2023.3.2, but you have dask 2023.4.0 which is incompatible.\ncudf 23.4.0 requires protobuf<4.22,>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\nbeatrix-jupyterlab 2023.46.184821 requires jupyter-server~=1.16, but you have jupyter-server 2.5.0 which is incompatible.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 10.0.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.22.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport tensorflow as tf\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:20.577759Z","iopub.execute_input":"2023-05-24T05:23:20.578962Z","iopub.status.idle":"2023-05-24T05:23:27.402851Z","shell.execute_reply.started":"2023-05-24T05:23:20.578920Z","shell.execute_reply":"2023-05-24T05:23:27.401814Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:27.404565Z","iopub.execute_input":"2023-05-24T05:23:27.405335Z","iopub.status.idle":"2023-05-24T05:23:29.402111Z","shell.execute_reply.started":"2023-05-24T05:23:27.405298Z","shell.execute_reply":"2023-05-24T05:23:29.401048Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.403511Z","iopub.execute_input":"2023-05-24T05:23:29.405769Z","iopub.status.idle":"2023-05-24T05:23:29.426822Z","shell.execute_reply.started":"2023-05-24T05:23:29.405735Z","shell.execute_reply":"2023-05-24T05:23:29.425910Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.428131Z","iopub.execute_input":"2023-05-24T05:23:29.429155Z","iopub.status.idle":"2023-05-24T05:23:29.443021Z","shell.execute_reply.started":"2023-05-24T05:23:29.429120Z","shell.execute_reply":"2023-05-24T05:23:29.441482Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                      id                                       comment_text  \\\n159566  ffe987279560d7ff  \":::::And for the second time of asking, when ...   \n159567  ffea4adeee384e90  You should be ashamed of yourself \\n\\nThat is ...   \n159568  ffee36eab5c267c9  Spitzer \\n\\nUmm, theres no actual article for ...   \n159569  fff125370e4aaaf3  And it looks like it was actually you who put ...   \n159570  fff46fc426af1f9a  \"\\nAnd ... I really don't think you understand...   \n\n        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n159566      0             0        0       0       0              0  \n159567      0             0        0       0       0              0  \n159568      0             0        0       0       0              0  \n159569      0             0        0       0       0              0  \n159570      0             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>159566</th>\n      <td>ffe987279560d7ff</td>\n      <td>\":::::And for the second time of asking, when ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159567</th>\n      <td>ffea4adeee384e90</td>\n      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159568</th>\n      <td>ffee36eab5c267c9</td>\n      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159569</th>\n      <td>fff125370e4aaaf3</td>\n      <td>And it looks like it was actually you who put ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>159570</th>\n      <td>fff46fc426af1f9a</td>\n      <td>\"\\nAnd ... I really don't think you understand...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.iloc[100]['comment_text']","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.444478Z","iopub.execute_input":"2023-05-24T05:23:29.444932Z","iopub.status.idle":"2023-05-24T05:23:29.453597Z","shell.execute_reply.started":"2023-05-24T05:23:29.444902Z","shell.execute_reply":"2023-05-24T05:23:29.452702Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'However, the Moonlite edit noted by golden daph was me (on optus ...)  Wake up wikkis.  So funny'"},"metadata":{}}]},{"cell_type":"code","source":"df[df.columns[2:]].iloc[5]","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.454889Z","iopub.execute_input":"2023-05-24T05:23:29.455864Z","iopub.status.idle":"2023-05-24T05:23:29.469511Z","shell.execute_reply.started":"2023-05-24T05:23:29.455830Z","shell.execute_reply":"2023-05-24T05:23:29.468543Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"toxic            0\nsevere_toxic     0\nobscene          0\nthreat           0\ninsult           0\nidentity_hate    0\nName: 5, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df[df['toxic']==1].head()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.474970Z","iopub.execute_input":"2023-05-24T05:23:29.475816Z","iopub.status.idle":"2023-05-24T05:23:29.495250Z","shell.execute_reply.started":"2023-05-24T05:23:29.475775Z","shell.execute_reply":"2023-05-24T05:23:29.494404Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                  id                                       comment_text  \\\n6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n\n    toxic  severe_toxic  obscene  threat  insult  identity_hate  \n6       1             1        1       0       1              0  \n12      1             0        0       0       0              0  \n16      1             0        0       0       0              0  \n42      1             0        1       0       1              1  \n43      1             0        1       0       1              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6</th>\n      <td>0002bcb3da6cb337</td>\n      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0005c987bdfc9d4b</td>\n      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>0007e25b2121310b</td>\n      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>001810bf8c45bf5f</td>\n      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>00190820581d90ce</td>\n      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.iloc[5]['comment_text']","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.496309Z","iopub.execute_input":"2023-05-24T05:23:29.496552Z","iopub.status.idle":"2023-05-24T05:23:29.505087Z","shell.execute_reply.started":"2023-05-24T05:23:29.496531Z","shell.execute_reply":"2023-05-24T05:23:29.504054Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'\"\\n\\nCongratulations from me as well, use the tools well. \\xa0· talk \"'"},"metadata":{}}]},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.506624Z","iopub.execute_input":"2023-05-24T05:23:29.507232Z","iopub.status.idle":"2023-05-24T05:23:29.514324Z","shell.execute_reply.started":"2023-05-24T05:23:29.507200Z","shell.execute_reply":"2023-05-24T05:23:29.512983Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"X = df['comment_text']\ny = df[df.columns[2:]].values","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.515946Z","iopub.execute_input":"2023-05-24T05:23:29.516676Z","iopub.status.idle":"2023-05-24T05:23:29.528980Z","shell.execute_reply.started":"2023-05-24T05:23:29.516634Z","shell.execute_reply":"2023-05-24T05:23:29.527733Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"MAX_FEATURES = 200000 # number of words in the vocab","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.530414Z","iopub.execute_input":"2023-05-24T05:23:29.531084Z","iopub.status.idle":"2023-05-24T05:23:29.535315Z","shell.execute_reply.started":"2023-05-24T05:23:29.531051Z","shell.execute_reply":"2023-05-24T05:23:29.534312Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"vectorizer = TextVectorization(max_tokens=MAX_FEATURES,\n                              output_sequence_length=1800,\n                              output_mode='int')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:29.536821Z","iopub.execute_input":"2023-05-24T05:23:29.537541Z","iopub.status.idle":"2023-05-24T05:23:33.348495Z","shell.execute_reply.started":"2023-05-24T05:23:29.537509Z","shell.execute_reply":"2023-05-24T05:23:33.347501Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"vectorizer.adapt(X.values)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:33.350125Z","iopub.execute_input":"2023-05-24T05:23:33.350821Z","iopub.status.idle":"2023-05-24T05:23:46.291032Z","shell.execute_reply.started":"2023-05-24T05:23:33.350782Z","shell.execute_reply":"2023-05-24T05:23:46.289971Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"vectorizer.get_vocabulary()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:46.293192Z","iopub.execute_input":"2023-05-24T05:23:46.293550Z","iopub.status.idle":"2023-05-24T05:23:52.272080Z","shell.execute_reply.started":"2023-05-24T05:23:46.293517Z","shell.execute_reply":"2023-05-24T05:23:52.271188Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"['',\n '[UNK]',\n 'the',\n 'to',\n 'of',\n 'and',\n 'a',\n 'you',\n 'i',\n 'is',\n 'that',\n 'in',\n 'it',\n 'for',\n 'this',\n 'not',\n 'on',\n 'be',\n 'as',\n 'have',\n 'are',\n 'your',\n 'with',\n 'if',\n 'article',\n 'was',\n 'or',\n 'but',\n 'page',\n 'my',\n 'an',\n 'from',\n 'by',\n 'do',\n 'at',\n 'about',\n 'me',\n 'so',\n 'wikipedia',\n 'can',\n 'what',\n 'there',\n 'all',\n 'has',\n 'will',\n 'talk',\n 'please',\n 'would',\n 'its',\n 'no',\n 'one',\n 'just',\n 'like',\n 'they',\n 'he',\n 'dont',\n 'which',\n 'any',\n 'been',\n 'should',\n 'more',\n 'we',\n 'some',\n 'other',\n 'who',\n 'see',\n 'here',\n 'also',\n 'his',\n 'think',\n 'im',\n 'because',\n 'know',\n 'how',\n 'am',\n 'people',\n 'why',\n 'edit',\n 'articles',\n 'only',\n 'out',\n 'up',\n 'when',\n 'were',\n 'use',\n 'then',\n 'may',\n 'time',\n 'did',\n 'them',\n 'now',\n 'being',\n 'their',\n 'than',\n 'thanks',\n 'even',\n 'get',\n 'make',\n 'good',\n 'had',\n 'very',\n 'information',\n 'does',\n 'could',\n 'well',\n 'want',\n 'such',\n 'sources',\n 'way',\n 'name',\n 'these',\n 'deletion',\n 'pages',\n 'first',\n 'help',\n 'new',\n 'editing',\n 'source',\n 'go',\n 'need',\n 'say',\n 'section',\n 'edits',\n 'again',\n 'thank',\n 'where',\n 'user',\n 'made',\n 'many',\n 'much',\n 'really',\n 'used',\n 'most',\n 'discussion',\n 'find',\n 'same',\n 'ive',\n 'deleted',\n 'into',\n 'fuck',\n 'those',\n 'work',\n 'since',\n 'before',\n 'after',\n 'point',\n 'add',\n 'look',\n 'right',\n 'read',\n 'image',\n 'take',\n 'still',\n 'over',\n 'someone',\n 'him',\n 'two',\n 'back',\n 'too',\n 'fact',\n 'link',\n 'said',\n 'own',\n 'something',\n 'going',\n 'youre',\n 'blocked',\n 'list',\n 'stop',\n 'without',\n 'content',\n 'hi',\n 'under',\n 'editors',\n 'our',\n 'block',\n 'thats',\n 'us',\n 'added',\n 'utc',\n 'history',\n 'another',\n 'doesnt',\n 'removed',\n 'might',\n 'note',\n 'however',\n 'sure',\n 'place',\n 'never',\n 'done',\n 'welcome',\n 'her',\n 'case',\n 'put',\n 'personal',\n 'seems',\n 'reason',\n 'better',\n 'using',\n 'yourself',\n 'cant',\n 'actually',\n 'ask',\n 'comment',\n 'while',\n 'vandalism',\n 'feel',\n 'question',\n 'anything',\n 'believe',\n 'person',\n 'links',\n 'things',\n 'both',\n 'didnt',\n 'comments',\n 'best',\n 'ill',\n 'part',\n 'she',\n 'hope',\n 'policy',\n 'against',\n 'off',\n 'keep',\n 'already',\n 'free',\n 'wiki',\n 'thing',\n 'nothing',\n 'change',\n 'wrong',\n 'though',\n 'problem',\n 'remove',\n 'little',\n 'subject',\n '•',\n 'others',\n 'trying',\n 'tag',\n 'copyright',\n 'must',\n 'understand',\n 'above',\n 'few',\n 'anyone',\n 'speedy',\n 'last',\n 'issue',\n 'give',\n 'questions',\n 'agree',\n 'rather',\n 'years',\n 'let',\n '2',\n 'different',\n 'editor',\n 'long',\n 'reliable',\n 'making',\n 'world',\n 'come',\n 'sorry',\n 'isnt',\n 'reference',\n 'mean',\n 'continue',\n 'try',\n 'references',\n 'found',\n 'doing',\n 'text',\n 'great',\n 'leave',\n 'says',\n 'got',\n 'probably',\n 'english',\n 'original',\n 'every',\n '1',\n 'simply',\n 'word',\n 'users',\n 'fair',\n 'hello',\n 'either',\n 'check',\n 'least',\n 'adding',\n 'ip',\n 'show',\n 'site',\n 'state',\n 'else',\n 'delete',\n 'consensus',\n 'enough',\n 'request',\n 'far',\n 'opinion',\n 'created',\n 'around',\n 'life',\n 'day',\n 'between',\n 'through',\n 'example',\n 'view',\n 'yes',\n 'reverted',\n 'yet',\n 'etc',\n 'id',\n 'matter',\n 'shit',\n 'u',\n 'war',\n 'notable',\n 'contributions',\n 'given',\n 'thought',\n 'material',\n 'book',\n 'admin',\n 'write',\n 'post',\n 'down',\n 'account',\n 'clearly',\n 'having',\n 'encyclopedia',\n 'lot',\n 'support',\n 'real',\n 'bad',\n 'message',\n 'needs',\n 'images',\n 'tell',\n 'seem',\n 'called',\n 'maybe',\n 'evidence',\n 'instead',\n 'ever',\n '3',\n 'correct',\n 'saying',\n 'clear',\n 'always',\n 'number',\n 'important',\n 'further',\n 'quite',\n 'perhaps',\n 'old',\n '—',\n 'true',\n 'until',\n 'hate',\n 'states',\n 'whether',\n 'consider',\n 'written',\n 'claim',\n 'language',\n 'media',\n 'bit',\n 'once',\n 'guidelines',\n 'term',\n 'criteria',\n 'research',\n 'nigger',\n 'version',\n 'times',\n 'website',\n 'getting',\n 'fucking',\n 'theres',\n 'review',\n 'mention',\n 'pov',\n 'oh',\n 'makes',\n 'several',\n 'revert',\n 'considered',\n 'changes',\n 'cannot',\n 'words',\n 'idea',\n 'title',\n 'suck',\n 'address',\n 'notice',\n 'based',\n 'top',\n 'following',\n 'current',\n 'each',\n 'listed',\n 'means',\n 'possible',\n 'group',\n 'facts',\n 'regarding',\n 'care',\n 'rules',\n 'second',\n 'main',\n 'template',\n 'mentioned',\n 'general',\n 'year',\n 'attack',\n 'kind',\n 'whole',\n 'course',\n 'statement',\n 'left',\n 'hey',\n 'date',\n 'include',\n 'seen',\n 'three',\n 'issues',\n 'start',\n 'ass',\n 'ok',\n 'end',\n 'wikipedias',\n 'call',\n 'less',\n 'topic',\n 'gay',\n 'suggest',\n 'man',\n 'including',\n 'happy',\n 'sense',\n 'provide',\n 'create',\n 'big',\n 'days',\n 'myself',\n 'american',\n 'redirect',\n 'known',\n 'sentence',\n 'move',\n 'appropriate',\n 'changed',\n 'love',\n 'notability',\n 'explain',\n 'started',\n 'included',\n 'removing',\n 'project',\n 'anyway',\n 'info',\n 'mind',\n 'school',\n '2005',\n 'next',\n 'looking',\n 'although',\n 'picture',\n 'relevant',\n 'four',\n 'die',\n 'sign',\n 'answer',\n 'style',\n 'away',\n 'per',\n 'order',\n 'warning',\n 'wont',\n 'recent',\n 'youve',\n 'interest',\n 'community',\n 'summary',\n 'later',\n 'lol',\n 'claims',\n 'currently',\n 'discuss',\n 'interested',\n 'policies',\n 'attacks',\n 'especially',\n 'wish',\n 'wrote',\n 'able',\n 'specific',\n 'public',\n 'taken',\n 'writing',\n 'neutral',\n 'full',\n 'names',\n 'within',\n '4',\n 'position',\n 'related',\n 'below',\n 'line',\n 'wanted',\n 'during',\n 'appears',\n 'stuff',\n 'certainly',\n 'official',\n 'nice',\n 'itself',\n 'faith',\n 'everyone',\n 'wasnt',\n 'live',\n 'report',\n 'completely',\n 'according',\n 'unless',\n 'common',\n 'pretty',\n 'country',\n 'everything',\n 'looks',\n 'due',\n 'single',\n 'hes',\n 'process',\n 'contribs',\n 'news',\n 'involved',\n 'god',\n 'fat',\n 'therefore',\n 'obviously',\n 'remember',\n 'lead',\n 'hard',\n 'admins',\n 'came',\n 'edited',\n 'web',\n 'stay',\n 'learn',\n 'response',\n 'future',\n 'past',\n 'asked',\n 'truth',\n 'reading',\n 'power',\n '2006',\n 'stupid',\n 'entry',\n 'quote',\n 'posted',\n 'nor',\n 'talking',\n 'placed',\n '5',\n 'ago',\n 'similar',\n 'email',\n 'game',\n 'published',\n 'exactly',\n 'today',\n 'reasons',\n 'paragraph',\n 'faggot',\n 'city',\n 'argument',\n 'whatever',\n 'system',\n 'working',\n 'false',\n 'sandbox',\n 'moron',\n 'political',\n 'noticed',\n 'useful',\n 'havent',\n 'guy',\n 'high',\n 'regards',\n 'united',\n 'guess',\n 'appreciate',\n 'particular',\n 'deleting',\n 'form',\n 'books',\n 'government',\n 'dispute',\n 'five',\n 'british',\n 'reverting',\n 'major',\n 'problems',\n 'national',\n 'party',\n 'provided',\n 'often',\n 'ones',\n 'become',\n 'lets',\n 'tried',\n 'side',\n 'administrator',\n 'along',\n 'reply',\n 'almost',\n 'needed',\n 'stated',\n 'rule',\n 'took',\n 'search',\n 'knowledge',\n 'banned',\n 'cheers',\n 'taking',\n 'vandalize',\n '–',\n 'certain',\n '2007',\n 'username',\n 'fine',\n 'status',\n 'law',\n 'points',\n 'company',\n 'otherwise',\n 'uploaded',\n 'terms',\n 'explanation',\n 'generally',\n 'sort',\n 'entire',\n 'shows',\n 'description',\n 'whats',\n 'recently',\n 'follow',\n 'guys',\n '2008',\n 'likely',\n 'film',\n 'present',\n 'aware',\n 'saw',\n 'definition',\n 'cited',\n 'alone',\n 'google',\n 'music',\n 'soon',\n 'indeed',\n 'decide',\n 'ban',\n 'wp',\n 'appear',\n 'views',\n 'week',\n 'open',\n 'citation',\n 'contributing',\n 'actual',\n 'set',\n 'interesting',\n 'piece',\n 'c',\n 'short',\n 'white',\n 'told',\n 'theory',\n 'area',\n 'improve',\n 'external',\n 'small',\n 'story',\n 'contact',\n 'simple',\n '2004',\n 'various',\n 'allowed',\n 'moved',\n 'test',\n 'internet',\n 'obvious',\n 'family',\n 'band',\n 'attention',\n 'arent',\n 'proposed',\n 'jew',\n 'themselves',\n 'members',\n 'wouldnt',\n 'result',\n 'disagree',\n 'thus',\n 'cunt',\n 'went',\n 'type',\n 'sites',\n 'ie',\n 'context',\n 'mr',\n 'previous',\n 'nonsense',\n 'actions',\n 'tags',\n 'cite',\n 'works',\n '10',\n 'citations',\n 'jews',\n 'university',\n 're',\n 'enjoy',\n 'conflict',\n 'hours',\n 'shouldnt',\n 'proper',\n 'bias',\n 'category',\n 'job',\n 'longer',\n 'file',\n 'together',\n 'hell',\n 'sourced',\n 'sucks',\n 'addition',\n 'happened',\n 'avoid',\n 'automatically',\n 'author',\n 'valid',\n 'black',\n 'creating',\n 'deal',\n 'worked',\n 'npov',\n 'goes',\n 'himself',\n 'seriously',\n 'john',\n 'death',\n 'proof',\n 'respect',\n 'bitch',\n 'science',\n 'human',\n 'biased',\n 'comes',\n 'helpful',\n 'large',\n 'accepted',\n 'available',\n 'exist',\n 'series',\n 'tildes',\n 'opinions',\n 'hand',\n '6',\n 'indicate',\n 'sections',\n 'rights',\n 'necessary',\n 'act',\n 'meaning',\n 'attempt',\n 'accept',\n 'personally',\n 'statements',\n 'violation',\n 'months',\n 'criticism',\n 'accurate',\n 'action',\n 'usually',\n 'unblock',\n 'german',\n 'pig',\n 'cause',\n 'yeah',\n 'living',\n 'copy',\n 'debate',\n 'upon',\n 'assume',\n 'july',\n 'calling',\n 'standard',\n 'video',\n 'play',\n 'rest',\n 'tagged',\n 'doubt',\n 'sex',\n 'multiple',\n 'theyre',\n 'historical',\n 'serious',\n 'details',\n 'dick',\n 'youll',\n 'separate',\n 'manual',\n 'record',\n 'blocking',\n 'afd',\n 'explaining',\n 'situation',\n 'refer',\n 'wikiproject',\n 'heard',\n 'online',\n 'level',\n 'fix',\n 'asking',\n '7',\n 'complete',\n 'speak',\n 'lack',\n 'messages',\n 'none',\n 'prove',\n 'third',\n 'subjects',\n 'church',\n 'apparently',\n '2009',\n 'south',\n 'rationale',\n 'bullshit',\n 'data',\n 'directly',\n 'august',\n 'period',\n 'legal',\n 'behavior',\n 'difference',\n 'contribute',\n 'greek',\n 'huge',\n 'gets',\n 'wikipedian',\n 'couple',\n 'supposed',\n 'among',\n 'early',\n 'except',\n 'march',\n 'close',\n 'quality',\n 'space',\n 'meant',\n 'countries',\n 'run',\n 'team',\n 'uses',\n 'military',\n 'b',\n 'changing',\n 'existing',\n 'specifically',\n 'significant',\n '2010',\n 'pillars',\n 'fish',\n 'incorrect',\n 'culture',\n 'described',\n 'produce',\n 'jewish',\n '24',\n 'uk',\n 'disruptive',\n 'd',\n 'field',\n 'error',\n 'india',\n 'head',\n 'primary',\n 'friend',\n 'earlier',\n 'sometimes',\n 'outside',\n '20',\n 'purpose',\n 'administrators',\n 'modern',\n 'photo',\n 'table',\n 'particularly',\n 't',\n 'release',\n 'gave',\n 'box',\n 'cases',\n 'inclusion',\n 'born',\n 'pictures',\n 'readers',\n 'june',\n 'character',\n 'vote',\n 'okay',\n 'groups',\n 'anonymous',\n 'abuse',\n 'arguments',\n 'business',\n 'shall',\n 'sock',\n 'tutorial',\n 'january',\n 'friends',\n 'numbers',\n 'control',\n 'thinking',\n 'member',\n 'linked',\n 'happen',\n 'reported',\n 'contest',\n 'coming',\n 'takes',\n 'concerns',\n 'allow',\n 'wait',\n 'majority',\n 'giving',\n '8',\n 'bring',\n 'eg',\n 'worth',\n 'kill',\n 'totally',\n 'red',\n 'force',\n 'decided',\n 'discussed',\n 'house',\n 'finally',\n 'absolutely',\n 'putting',\n 'scientific',\n 'respond',\n 'mistake',\n 'decision',\n 'de',\n 'lost',\n 'entirely',\n '100',\n 'towards',\n 'merely',\n 'home',\n 'neither',\n 'dear',\n 'independent',\n 'international',\n 'song',\n 'balls',\n 'wants',\n 'possibly',\n 'unsigned',\n 'million',\n 'irrelevant',\n 'standards',\n 'april',\n '12',\n 'press',\n 'figure',\n 'organization',\n 'looked',\n 'inappropriate',\n 'chance',\n 'posting',\n 'population',\n 'advice',\n 'posts',\n 'north',\n 'events',\n 'unfortunately',\n 'named',\n 'album',\n ...]"},"metadata":{}}]},{"cell_type":"code","source":"vectorizer('Hello world, life is great')[:5]","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:52.276814Z","iopub.execute_input":"2023-05-24T05:23:52.279950Z","iopub.status.idle":"2023-05-24T05:23:52.428451Z","shell.execute_reply.started":"2023-05-24T05:23:52.279914Z","shell.execute_reply":"2023-05-24T05:23:52.427521Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<tf.Tensor: shape=(5,), dtype=int64, numpy=array([288, 263, 306,   9, 275])>"},"metadata":{}}]},{"cell_type":"code","source":"vectorized_text = vectorizer(X.values)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:52.433791Z","iopub.execute_input":"2023-05-24T05:23:52.437175Z","iopub.status.idle":"2023-05-24T05:23:57.396143Z","shell.execute_reply.started":"2023-05-24T05:23:52.437138Z","shell.execute_reply":"2023-05-24T05:23:57.395205Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\ndataset = dataset.cache()\ndataset = dataset.shuffle(160000)\ndataset = dataset.batch(16)\ndataset = dataset.prefetch(8)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:57.397566Z","iopub.execute_input":"2023-05-24T05:23:57.397916Z","iopub.status.idle":"2023-05-24T05:23:57.425461Z","shell.execute_reply.started":"2023-05-24T05:23:57.397884Z","shell.execute_reply":"2023-05-24T05:23:57.424580Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_X, batch_y = dataset.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:57.426687Z","iopub.execute_input":"2023-05-24T05:23:57.427246Z","iopub.status.idle":"2023-05-24T05:23:59.836474Z","shell.execute_reply.started":"2023-05-24T05:23:57.427214Z","shell.execute_reply":"2023-05-24T05:23:59.835389Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"train = dataset.take(int(len(dataset)*.7))\nval = dataset.skip(int(len(dataset)*.7)).take(int(len(dataset)*.2))\ntest = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:59.842532Z","iopub.execute_input":"2023-05-24T05:23:59.845778Z","iopub.status.idle":"2023-05-24T05:23:59.863884Z","shell.execute_reply.started":"2023-05-24T05:23:59.845742Z","shell.execute_reply":"2023-05-24T05:23:59.863050Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_generator = train.as_numpy_iterator()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:23:59.868936Z","iopub.execute_input":"2023-05-24T05:23:59.871952Z","iopub.status.idle":"2023-05-24T05:24:01.794842Z","shell.execute_reply.started":"2023-05-24T05:23:59.871920Z","shell.execute_reply":"2023-05-24T05:24:01.793701Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_generator.next()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:01.796042Z","iopub.execute_input":"2023-05-24T05:24:01.796429Z","iopub.status.idle":"2023-05-24T05:24:02.014327Z","shell.execute_reply.started":"2023-05-24T05:24:01.796391Z","shell.execute_reply":"2023-05-24T05:24:02.013274Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"(array([[  339,     3, 34809, ...,     0,     0,     0],\n        [  345,    82,     7, ...,     0,     0,     0],\n        [   14,     9,     2, ...,     0,     0,     0],\n        ...,\n        [    5,    55,   747, ...,     0,     0,     0],\n        [   33,    15, 11463, ...,     0,     0,     0],\n        [   76,    79,  1273, ...,     0,     0,     0]]),\n array([[0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0]]))"},"metadata":{}}]},{"cell_type":"markdown","source":"# 2. Create Sequential Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:02.018846Z","iopub.execute_input":"2023-05-24T05:24:02.019663Z","iopub.status.idle":"2023-05-24T05:24:02.032199Z","shell.execute_reply.started":"2023-05-24T05:24:02.019626Z","shell.execute_reply":"2023-05-24T05:24:02.031107Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n# Create the embedding layer\nmodel.add(Embedding(MAX_FEATURES+1, 32))\n# Bidirectional LSTM Layer\nmodel.add(Bidirectional(LSTM(32, activation='tanh')))\n# Features extractor Fully connected Layers\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n# Final layer\nmodel.add(Dense(6, activation='sigmoid'))","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:02.034058Z","iopub.execute_input":"2023-05-24T05:24:02.036143Z","iopub.status.idle":"2023-05-24T05:24:02.737418Z","shell.execute_reply.started":"2023-05-24T05:24:02.034791Z","shell.execute_reply":"2023-05-24T05:24:02.736389Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='BinaryCrossentropy', optimizer='Adam')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:02.739162Z","iopub.execute_input":"2023-05-24T05:24:02.739535Z","iopub.status.idle":"2023-05-24T05:24:02.758729Z","shell.execute_reply.started":"2023-05-24T05:24:02.739502Z","shell.execute_reply":"2023-05-24T05:24:02.757829Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:02.766099Z","iopub.execute_input":"2023-05-24T05:24:02.766372Z","iopub.status.idle":"2023-05-24T05:24:02.793442Z","shell.execute_reply.started":"2023-05-24T05:24:02.766347Z","shell.execute_reply":"2023-05-24T05:24:02.792773Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding (Embedding)       (None, None, 32)          6400032   \n                                                                 \n bidirectional (Bidirectiona  (None, 64)               16640     \n l)                                                              \n                                                                 \n dense (Dense)               (None, 128)               8320      \n                                                                 \n dense_1 (Dense)             (None, 256)               33024     \n                                                                 \n dense_2 (Dense)             (None, 128)               32896     \n                                                                 \n dense_3 (Dense)             (None, 6)                 774       \n                                                                 \n=================================================================\nTotal params: 6,491,686\nTrainable params: 6,491,686\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(train, epochs=1, validation_data=val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.history","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.731898Z","iopub.status.idle":"2023-05-24T05:24:43.732636Z","shell.execute_reply.started":"2023-05-24T05:24:43.732383Z","shell.execute_reply":"2023-05-24T05:24:43.732408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\npd.DataFrame(history.history).plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.733992Z","iopub.status.idle":"2023-05-24T05:24:43.734740Z","shell.execute_reply.started":"2023-05-24T05:24:43.734472Z","shell.execute_reply":"2023-05-24T05:24:43.734496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Make the prediction","metadata":{}},{"cell_type":"code","source":"batch = test.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.736061Z","iopub.status.idle":"2023-05-24T05:24:43.736754Z","shell.execute_reply.started":"2023-05-24T05:24:43.736501Z","shell.execute_reply":"2023-05-24T05:24:43.736524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_X, batch_y = test.as_numpy_iterator().next()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.738125Z","iopub.status.idle":"2023-05-24T05:24:43.738871Z","shell.execute_reply.started":"2023-05-24T05:24:43.738593Z","shell.execute_reply":"2023-05-24T05:24:43.738618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = (model.predict(batch_X) > 0.5).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.740206Z","iopub.status.idle":"2023-05-24T05:24:43.740946Z","shell.execute_reply.started":"2023-05-24T05:24:43.740684Z","shell.execute_reply":"2023-05-24T05:24:43.740709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns[2:]","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.742270Z","iopub.status.idle":"2023-05-24T05:24:43.742969Z","shell.execute_reply.started":"2023-05-24T05:24:43.742724Z","shell.execute_reply":"2023-05-24T05:24:43.742746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_text = vectorizer('I love you')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.744346Z","iopub.status.idle":"2023-05-24T05:24:43.745072Z","shell.execute_reply.started":"2023-05-24T05:24:43.744807Z","shell.execute_reply":"2023-05-24T05:24:43.744830Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.predict(np.expand_dims(input_text,0))","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.746551Z","iopub.status.idle":"2023-05-24T05:24:43.747278Z","shell.execute_reply.started":"2023-05-24T05:24:43.747013Z","shell.execute_reply":"2023-05-24T05:24:43.747037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = model.predict(batch_X)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.748723Z","iopub.status.idle":"2023-05-24T05:24:43.749420Z","shell.execute_reply.started":"2023-05-24T05:24:43.749176Z","shell.execute_reply":"2023-05-24T05:24:43.749198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = res.flatten()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.750641Z","iopub.status.idle":"2023-05-24T05:24:43.751354Z","shell.execute_reply.started":"2023-05-24T05:24:43.751109Z","shell.execute_reply":"2023-05-24T05:24:43.751132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.752591Z","iopub.status.idle":"2023-05-24T05:24:43.753296Z","shell.execute_reply.started":"2023-05-24T05:24:43.753058Z","shell.execute_reply":"2023-05-24T05:24:43.753081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Evaluate the Model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.754528Z","iopub.status.idle":"2023-05-24T05:24:43.755232Z","shell.execute_reply.started":"2023-05-24T05:24:43.754977Z","shell.execute_reply":"2023-05-24T05:24:43.755014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre =  Precision()\nre = Recall()\nacc = CategoricalAccuracy()","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.756457Z","iopub.status.idle":"2023-05-24T05:24:43.757192Z","shell.execute_reply.started":"2023-05-24T05:24:43.756913Z","shell.execute_reply":"2023-05-24T05:24:43.756936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in test.as_numpy_iterator():\n    # Unpack the batch\n    X_true, y_true = batch\n    # Make a prediction\n    yhat = model.predict(X_true)\n    \n    # Flatten the predictions\n    y_true = y_true.flatten()\n    yhat = yhat.flatten()\n    \n    pre.update_state(y_true, yhat)\n    re.update_state(y_true, yhat)\n    acc.update_state(y_true, yhat)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.758511Z","iopub.status.idle":"2023-05-24T05:24:43.759231Z","shell.execute_reply.started":"2023-05-24T05:24:43.758969Z","shell.execute_reply":"2023-05-24T05:24:43.758992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.760475Z","iopub.status.idle":"2023-05-24T05:24:43.761243Z","shell.execute_reply.started":"2023-05-24T05:24:43.760930Z","shell.execute_reply":"2023-05-24T05:24:43.760953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Test and Gradio","metadata":{}},{"cell_type":"code","source":"!pip install gradio jinja2","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.762545Z","iopub.status.idle":"2023-05-24T05:24:43.763318Z","shell.execute_reply.started":"2023-05-24T05:24:43.763041Z","shell.execute_reply":"2023-05-24T05:24:43.763066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gradio as gr","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.764621Z","iopub.status.idle":"2023-05-24T05:24:43.765331Z","shell.execute_reply.started":"2023-05-24T05:24:43.765087Z","shell.execute_reply":"2023-05-24T05:24:43.765110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('toxicity.h5')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.766557Z","iopub.status.idle":"2023-05-24T05:24:43.767298Z","shell.execute_reply.started":"2023-05-24T05:24:43.767025Z","shell.execute_reply":"2023-05-24T05:24:43.767048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('toxicity.h5')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.768589Z","iopub.status.idle":"2023-05-24T05:24:43.769294Z","shell.execute_reply.started":"2023-05-24T05:24:43.769052Z","shell.execute_reply":"2023-05-24T05:24:43.769075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_str = vectorizer('hey i just wanna kill you and make you feel low!')","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.770767Z","iopub.status.idle":"2023-05-24T05:24:43.771465Z","shell.execute_reply.started":"2023-05-24T05:24:43.771221Z","shell.execute_reply":"2023-05-24T05:24:43.771244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = model.predict(np.expand_dims(input_str, 0))","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.772723Z","iopub.status.idle":"2023-05-24T05:24:43.773453Z","shell.execute_reply.started":"2023-05-24T05:24:43.773209Z","shell.execute_reply":"2023-05-24T05:24:43.773232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns[2:]","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.774701Z","iopub.status.idle":"2023-05-24T05:24:43.775389Z","shell.execute_reply.started":"2023-05-24T05:24:43.775144Z","shell.execute_reply":"2023-05-24T05:24:43.775166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.776643Z","iopub.status.idle":"2023-05-24T05:24:43.777419Z","shell.execute_reply.started":"2023-05-24T05:24:43.777150Z","shell.execute_reply":"2023-05-24T05:24:43.777176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score_comment(comment):\n    vectorize_comment = vectorizer([comment])\n    results = model.predict(vectorize_comment)\n    \n    text = ''\n    for idx, col in enumerate(df.columns[2:]):\n        text += '{}: {}\\n'.format(col, results[0][idx]>0.5)\n        \n    return text","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.778732Z","iopub.status.idle":"2023-05-24T05:24:43.779434Z","shell.execute_reply.started":"2023-05-24T05:24:43.779192Z","shell.execute_reply":"2023-05-24T05:24:43.779215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interface = gr.Interface(fn=score_comment,\n                        inputs=gr_comp.Textbox(lines=2, placeholder='Comment to score'),\n                        outputs='text')\n","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.780675Z","iopub.status.idle":"2023-05-24T05:24:43.781368Z","shell.execute_reply.started":"2023-05-24T05:24:43.781124Z","shell.execute_reply":"2023-05-24T05:24:43.781147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interface.launch(share=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-24T05:24:43.782628Z","iopub.status.idle":"2023-05-24T05:24:43.783396Z","shell.execute_reply.started":"2023-05-24T05:24:43.783115Z","shell.execute_reply":"2023-05-24T05:24:43.783139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}